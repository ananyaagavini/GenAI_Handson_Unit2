{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Part 4a: Embeddings & Vector Space"
      ],
      "metadata": {
        "id": "hOKStFYw_izC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iou_Nv4J2DRs"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "%pip install python-dotenv langchain langchain-huggingface sentence-transformers langchain-community --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import os\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# Using a FREE, open-source model from Hugging Face\n",
        "# 'all-MiniLM-L6-v2' is small, fast, and very good for English.\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "CiTPOPDv2H17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector = embeddings.embed_query(\"Apple\")\n",
        "\n",
        "print(f\"Dimensionality: {len(vector)}\")\n",
        "print(f\"First 5 numbers: {vector[:5]}\")"
      ],
      "metadata": {
        "id": "vQe0_NzW2XSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "\n",
        "vec_cat = embeddings.embed_query(\"Cat\")\n",
        "vec_dog = embeddings.embed_query(\"Dog\")\n",
        "vec_car = embeddings.embed_query(\"Car\")\n",
        "\n",
        "print(f\"Cat vs Dog: {cosine_similarity(vec_cat, vec_dog):.4f}\")\n",
        "print(f\"Cat vs Car: {cosine_similarity(vec_cat, vec_car):.4f}\")"
      ],
      "metadata": {
        "id": "npo8YwKV7edt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unit 2 - Part 4b: Naive RAG Pipeline"
      ],
      "metadata": {
        "id": "_u1lbH-Q7klS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "%pip install python-dotenv --upgrade --quiet faiss-cpu langchain-huggingface sentence-transformers langchain-community langchain-google-genai\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
        "\n",
        "# Using the same free model as Part 4a\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "IXfQqxuV7iZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "docs = [\n",
        "    Document(page_content=\"Piyush's favorite food is Pizza with extra cheese.\"),\n",
        "    Document(page_content=\"The secret password to the lab is 'Blueberry'.\"),\n",
        "    Document(page_content=\"LangChain is a framework for developing applications powered by language models.\"),\n",
        "]"
      ],
      "metadata": {
        "id": "WcADF8Bk8UMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")\n",
        "\n",
        "\n",
        "docs = [\n",
        "    Document(page_content=\"Piyush's favorite food is Pizza with extra cheese.\"),\n",
        "    Document(page_content=\"The secret password to the lab is Blueberry.\"),\n",
        "    Document(page_content=\"LangChain is a framework for developing applications powered by language models.\"),\n",
        "]\n",
        "\n",
        "\n",
        "test_vector = embeddings.embed_query(\"test\")\n",
        "print(\"Embedding length:\", len(test_vector))\n",
        "\n",
        "\n",
        "vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "\n",
        "\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "print(\"FAISS working successfully\")\n"
      ],
      "metadata": {
        "id": "Bfx5gm5n-tcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "template = \"\"\"\n",
        "Answer based ONLY on the context below:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "result = chain.invoke(\"What is the secret password?\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "Ui60dBUR_IQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unit 2 - Part 4c: Deep Dive into Indexing Algorithms"
      ],
      "metadata": {
        "id": "JkQVaHSy_MVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "d = 128\n",
        "nb = 10000\n",
        "xb = np.random.random((nb, d)).astype('float32')"
      ],
      "metadata": {
        "id": "eK3QWg4F_JJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = faiss.IndexFlatL2(d)\n",
        "index.add(xb)\n",
        "print(f\"Flat Index contains {index.ntotal} vectors\")"
      ],
      "metadata": {
        "id": "uCNYuWJ0_P1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlist = 100\n",
        "quantizer = faiss.IndexFlatL2(d)\n",
        "index_ivf = faiss.IndexIVFFlat(quantizer, d, nlist)\n",
        "\n",
        "\n",
        "index_ivf.train(xb)\n",
        "index_ivf.add(xb)"
      ],
      "metadata": {
        "id": "MQmDwbEG_S2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M = 16\n",
        "index_hnsw = faiss.IndexHNSWFlat(d, M)\n",
        "index_hnsw.add(xb)"
      ],
      "metadata": {
        "id": "Ink3mpEO_ViX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = 8\n",
        "index_pq = faiss.IndexPQ(d, m, 8)\n",
        "index_pq.train(xb)\n",
        "index_pq.add(xb)\n",
        "print(\"PQ Compression complete. RAM usage minimized.\")"
      ],
      "metadata": {
        "id": "9PJ4GoUS_ZSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "ZRkZs7Ju8ZQN"
      }
    }
  ]
}